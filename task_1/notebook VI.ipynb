{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0781310-09c9-4917-aa61-b0451fe5ce1e",
   "metadata": {},
   "source": [
    "In this notebook, I will:\n",
    "\n",
    "1. build a __ResNet-15__ architecture from scratch.\n",
    "\n",
    "2. utilize a learning rate scheduler.\n",
    "\n",
    "3. eliminate stacking operation from Dataset transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f6f784-cf37-497e-8c1e-fce916c3301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from random import shuffle\n",
    "\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908d9dee-3ffb-4918-90b2-c73b4a98492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harkhymadhe/miniforge3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/harkhymadhe/miniforge3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9d2464-c29c-470f-8947-413a3b18b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "electron_file = \"dataset/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\"\n",
    "photon_file = \"dataset/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd203d3-02e7-408a-b1fa-a622cb092207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "electron_data = h5py.File(name = electron_file)\n",
    "photon_data = h5py.File(name = photon_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa175725-4635-4a00-b730-4edbc0240686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X', 'y']>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electron_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4be289-61a9-4623-9817-3c63a6fab89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249000, 32, 32, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature shape\n",
    "electron_data['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfbab31f-2abd-4e40-88b1-5e5170f0f08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target shape\n",
    "electron_data['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e1e3e2-19f5-49cd-9122-e78d86c49679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249000, 32, 32, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature shape\n",
    "photon_data['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6387d195-d358-4f60-8817-8f8e31fcaf95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target shape\n",
    "photon_data['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea872004-4357-4a98-9be3-fe0ebec26072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target shape\n",
    "photon_data['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9aa0a3-6b4d-49dd-a2fc-19d4d113879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5_to_numpy(h5_file):\n",
    "    X, y = h5_file[\"X\"], h5_file[\"y\"]\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d050ea5-3270-44f7-bbb0-f34a9be21431",
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_data = h5_to_numpy(electron_data)\n",
    "photon_data = h5_to_numpy(photon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5367096c-ac97-4ef9-be47-28aa48a892bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([electron_data[0], photon_data[0]], axis = 0)\n",
    "targets = np.concatenate([electron_data[1].reshape(-1, 1), photon_data[1].reshape(-1, 1)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed6362c6-877c-489c-a656-a2e58dfe805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del electron_data\n",
    "del photon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "725bf693-9df7-4052-a1f9-c3930d1bd0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45457e4e-5392-4dbe-81c1-77ffd8eca96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6633f8a1-6408-44fa-8dd1-f5df1a56083e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 32, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e76741-077d-4bd2-84d4-71022983fe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf27ba1d-c663-46d6-9011-6854c9c117d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b11f1e-473e-4970-afc9-80a765525cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6995dd75-8ced-4dfb-9527-338d496109ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a084485c-4ec8-4c3b-a7b6-0e4a7bbdbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9241b176-7df0-4e28-b9f7-e9070ca906b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = train_test_split(pd.DataFrame(targets), test_size = .2, shuffle = True, stratify = targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c147ca9-9fba-49d1-a662-6a3b1f84b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = y_train.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2db04285-56ee-4b43-8540-ada166f4a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = y_test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b913e89-37d5-4ee1-9cc3-4caaeddec812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 49090, 304346, 414673, ..., 241572, 273851, 244299])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f6b7564-7243-4b7a-964b-73e5e64803ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([329079,  46482, 120159, ..., 469713, 375212,  94085])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d378a1-9619-4e5b-8976-4ad96789f234",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b89d9d3-1f5c-4d45-93d1-b8cb406a2db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2779698"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62f2a6b1-997a-492b-844b-6ee690edfd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.512557"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f037e2ef-f36b-4d00-8cb1-44ca0648f53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00047892798"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00585419-fddc-4573-ad03-9d74cc5dad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb955d-5507-4707-bd69-f720a6240551",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcb09d-87c0-4a86-b298-7e560708b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(data[0].mean(axis = -1), axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167e92f-92c0-4bcf-a780-36fd3bd4438c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af84a408-3e78-4f7f-b6a2-808413a504e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_particle(index):\n",
    "    img1 = data[index]\n",
    "    label1 = targets[index]\n",
    "    label1 = \"electron\" if label1 == 1 else \"photon\"\n",
    "\n",
    "    img2 = data[-index]\n",
    "    label2 = targets[-index]\n",
    "    label2 = \"electron\" if label2 == 1 else \"photon\"\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 7))\n",
    "\n",
    "    img1 = np.concatenate([img1, np.expand_dims(img1.mean(axis = -1), axis = -1)], axis = -1)\n",
    "    img2 = np.concatenate([img2, np.expand_dims(img2.mean(axis = -1), axis = -1)], axis = -1)\n",
    "    \n",
    "    # Histogram plots\n",
    "    axes[0,0].hist(img1[:, :, :2].flatten(), bins = 255)\n",
    "    axes[0,1].hist(img2[:, :, :2].flatten(), bins = 255)\n",
    "\n",
    "    axes[0,0].set_title(f\"Histogram plot of {label1} particle\")\n",
    "    axes[0,1].set_title(f\"Histogram plot of {label2} particle\")\n",
    "\n",
    "    axes[0,0].set_xticks([]); axes[0,0].set_yticks([])\n",
    "    axes[0,1].set_xticks([]); axes[0,1].set_yticks([])\n",
    "\n",
    "    # Hit energy\n",
    "    axes[1,0].imshow(img1[:, :, 0])\n",
    "    axes[1,1].imshow(img2[:, :, 0])\n",
    "\n",
    "    axes[1,0].set_title(f\"Hit energy of {label1} particle\")\n",
    "    axes[1,1].set_title(f\"Hit energy of {label2} particle\")\n",
    "\n",
    "    axes[1,0].set_xticks([]); axes[1,0].set_yticks([])\n",
    "    axes[1,1].set_xticks([]); axes[1,1].set_yticks([])\n",
    "\n",
    "    # Time to hit\n",
    "\n",
    "    axes[2,0].imshow(img1[:, :, 1])\n",
    "    axes[2,1].imshow(img2[:, :, 1])\n",
    "\n",
    "    axes[2,0].set_title(f\"Time to hit for {label1} particle\")\n",
    "    axes[2,1].set_title(f\"Time to hit for {label2} particle\")\n",
    "    \n",
    "    axes[2,0].set_xticks([]); axes[2,0].set_yticks([])\n",
    "    axes[2,1].set_xticks([]); axes[2,1].set_yticks([])\n",
    "    \n",
    "    plt.show(); plt.close(\"all\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99347dbf-0cf3-441e-87f6-c391e0fdfbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_particle(index = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0517b-f853-42d8-a7b3-7ae2df4e456c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded17c0-f5bb-4148-afa7-531e402bb771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd567cf1-9b56-458e-92fb-85702bed9dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f078d-9164-4ecc-9902-980f541f0284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60c38b-7a31-4869-9591-b503640195cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc17bfe-93a6-4d3f-907a-3bbba424c920",
   "metadata": {},
   "source": [
    "data[:, :, :, 0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf71186-96f4-438a-99ff-a7420c66f582",
   "metadata": {},
   "source": [
    "data[:, :, :, 0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5a27b-2975-4e79-abb1-02c2a70da2c5",
   "metadata": {},
   "source": [
    "data[:, :, :, 1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5b18d-8453-4b50-bb54-525f63bdbf8a",
   "metadata": {},
   "source": [
    "data[:, :, :, 1].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31749aa-fb74-4044-98eb-93995d9d5420",
   "metadata": {},
   "source": [
    "data[:, :, :, 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffc4a9-b73f-4f24-9ca2-8fda30118f22",
   "metadata": {},
   "source": [
    "(data[:, :, :, 0] + data[:, :, :, 1]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae81c7e-4094-4383-84aa-9e08aae20dcb",
   "metadata": {},
   "source": [
    "(data[:, :, :, 0] + data[:, :, :, 1]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697da922-4acd-4000-8aac-e8545c9abd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.001219672, -0.0002618075, 0.0009578699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828b371-bab5-41e2-acb0-8ab870b7ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = [0.023721104, 0.06738354, 0.07137743]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f9d1a-b2e7-45e3-8238-8f81ed852c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean[0] + mean[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3860244-3b46-46fd-b165-74df1c5507ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01932b-e7ad-4d3f-a856-e7b495814fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0cbe1-be72-4142-8ed4-ff6a4c0a3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef18d5d-645a-46ff-beaa-7403c12cf17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(data).to(DEVICE)\n",
    "targets = torch.tensor(targets, dtype = torch.int64).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49554db1-ad50-47ab-9e1d-d058b412972e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca0f04-c923-4866-961e-61cb5befe310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test samples\n",
    "train_data, test_data = data[train_indices], data[test_indices]\n",
    "train_targets, test_targets = targets[train_indices], targets[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b574e-4d2c-40b1-8303-fb0b4e987a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b248548-af2a-4185-b7de-96e717658958",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e1cf8-928b-4cad-856a-7bae264429cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and test datasets\n",
    "train_dataset = TensorDataset(train_data.permute(0, 3, 1, 2), train_targets)\n",
    "test_dataset = TensorDataset(test_data.permute(0, 3, 1, 2), test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa36ded-07dd-41e5-bc3c-a669c548e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0e627-e08a-4072-8f61-a5d0657e6b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf509e-6088-4467-86bb-4cf9527821bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataset(Dataset):\n",
    "    def __init__(self, dataset, transform = None):\n",
    "        self.dataset = dataset\n",
    "        if transform is None:\n",
    "            transform = T.Compose(\n",
    "                [\n",
    "                    T.Lambda(lambda x: torch.cat([x, x.mean(dim = 0, keepdim = True)], dim = 0).squeeze()),\n",
    "                    T.RandomAdjustSharpness(\n",
    "                        sharpness_factor = torch.randint(low = 0, high = 10, size = (1,)).item(),\n",
    "                        p = torch.rand(size = (1,)).item(),\n",
    "                    ),\n",
    "                    # T.RandomInvert(),\n",
    "                    # T.Normalize(mean = mean, std = std)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.dataset[index]\n",
    "        return self.transform(img), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3349d-f0b0-4b0b-b4b0-dc1351d256b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and test datasets\n",
    "train_dataset = ParticleDataset(dataset = train_dataset)\n",
    "test_dataset = ParticleDataset(dataset = test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1074e6-336a-4bc1-89e9-a84c0d58c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53392c69-c865-4c5b-beff-e31bd868d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27c831-a831-4af2-9d19-bfb42db631ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_dataset[1000][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0029fa0-6328-41ad-a888-f8834fcbb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49d983-3c11-4b54-a151-06d0e9d39dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65e923-8964-4e15-86fd-263a0c7750ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2e994-8120-457e-b70c-08682f8227e0",
   "metadata": {},
   "source": [
    "Next, I define dataloaders from the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53db2d2-1721-4575-9a13-3010623161db",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_dl = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf7a85-ea16-4139-b391-b0323c4e8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f23939-201b-4fdf-925e-420c101e550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2823f-3475-499d-a1dc-ef24f538d6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5423d9-2446-4b8e-9a1f-af678b56dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c579a-f7e3-4076-83e1-677ed9919c63",
   "metadata": {},
   "source": [
    "### Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5cd25-e1e1-4e2c-b428-2a9e571af97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size = 3, stride = 1, padding = 1, p = .5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "        self.p = p\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = self.in_channel,\n",
    "            out_channels = self.out_channel,\n",
    "            stride = self.stride,\n",
    "            kernel_size = self.kernel_size,\n",
    "            padding = self.padding\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.out_channel)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.dropout = nn.Dropout2d(p = self.p)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = self.out_channel,\n",
    "            out_channels = self.out_channel,\n",
    "            stride = self.stride,\n",
    "            kernel_size = self.kernel_size,\n",
    "            padding = self.padding\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channel)\n",
    "\n",
    "        if self.in_channel != self.out_channel:\n",
    "            upsample1 = nn.Conv2d(\n",
    "                in_channels = self.in_channel,\n",
    "                out_channels = self.out_channel,\n",
    "                stride = self.stride,\n",
    "                kernel_size = self.kernel_size,\n",
    "                padding = self.padding\n",
    "            )\n",
    "            upsample2 = nn.Conv2d(\n",
    "                in_channels = self.out_channel,\n",
    "                out_channels = self.out_channel,\n",
    "                stride = self.stride,\n",
    "                kernel_size = self.kernel_size,\n",
    "                padding = self.padding\n",
    "            )\n",
    "\n",
    "            self.upsample = nn.Sequential(\n",
    "                upsample1,\n",
    "                upsample2\n",
    "            )\n",
    "        else:\n",
    "            self.upsample = nn.Identity()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ = self.conv1(x)\n",
    "        x_ = self.bn1(x_)\n",
    "        \n",
    "        x_ = self.relu(x_)\n",
    "        x_ = self.dropout(x_)\n",
    "\n",
    "        x_ = self.conv2(x_)\n",
    "        x_ = self.bn2(x_)\n",
    "        \n",
    "        return self.upsample(x) + x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489b400-d4fd-41a4-aeed-d3f062741ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channel = 512, out_features = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channel = out_channel\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        blocks = nn.Sequential()\n",
    "\n",
    "        for i, channel in enumerate(self.in_channels[:-1]):\n",
    "            block = BasicBlock(\n",
    "                in_channel = channel,\n",
    "                out_channel = self.in_channels[i+1],\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 1\n",
    "            )\n",
    "            blocks.add_module(f\"block{i+1}\", block)\n",
    "\n",
    "        self.blocks = blocks\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(out_features = self.out_channel),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.LazyLinear(out_features = self.out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710176f2-af3b-4a07-997d-51cb480abad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596accbb-d1b5-4a53-859c-aaa324554b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = [image_channels] + [16, 32,] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8cac3-019a-4771-9e56-10396abfed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac106e-8150-4c07-be6f-710aaf6603fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59104a59-2c81-405c-b4c5-51f27a763c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ParticleModel(in_channels = in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74f777-3d22-4121-822d-0ce4703ed056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bb9d4-da99-4d68-8add-0995ea1157ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.randn(8, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add284e8-731e-4d2c-9116-77c63fe9dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8958f7-c3e1-4dd4-9b68-31232888bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a743b-d2f8-4d9a-893b-a222d89f4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d5f63-db4d-470d-8e73-5926e125e0ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b51c95-fa29-4e7c-a847-4608418a8481",
   "metadata": {},
   "source": [
    "Now, I define a function to initialize model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d997f6-0c51-4023-9474-94ddd1739811",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49302fd7-68ab-46d6-b140-81040e5ab47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4083b6-d461-43ca-81bd-977016c24bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for (name, weights) in filter(lambda x: x[1].requires_grad, model.named_parameters()):\n",
    "        # if name.split(\".\")[-1] not in [\"fc\", \"conv1\"]:\n",
    "        #     continue\n",
    "        try:\n",
    "            nn.init.kaiming_normal_(weights, nonlinearity = \"relu\")\n",
    "        except:\n",
    "            nn.init.normal_(weights, mean = 0., std = 0.05)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_l2_loss(model):\n",
    "    return sum([x ** 2 for x in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5558d6-a906-4581-99e8-418af4de7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "\n",
    "model = initialize_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a81ac-70fa-45c7-b745-3d476af3e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab6731-7f4c-4a09-98dc-6e93d1c6c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "l2_lambda = .3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# Optimizer hyperparameters\n",
    "LR = 1e-1\n",
    "FACTOR = 10\n",
    "AMSGRAD = False\n",
    "BETAS = (.9, .999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d81c61-1c91-4def-b92b-adfda8a565ef",
   "metadata": {},
   "source": [
    "In this notebook, the pretrained weights will be finetuned. This is in contrast to the previous one, where the weights were kept frozen. Also, the learing rate is increased from 1e-4 to 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642a379-eb85-4d39-b45d-9ac0db66645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(\n",
    "    params = [{\n",
    "        \"params\" : model.fc.parameters(),\n",
    "        \"lr\": LR\n",
    "    }],\n",
    "    lr=LR/FACTOR,\n",
    "    amsgrad = AMSGRAD,\n",
    "    betas = BETAS,\n",
    "    weight_decay = l2_lambda\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, patience = 2, min_lr = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c54c4-a495-404c-8e6a-ac170b348a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l2_loss(model):\n",
    "    l2_loss = torch.tensor(0.).cuda()\n",
    "    l2_loss += sum(map(lambda x: x.data.pow(2).sum(), filter(lambda x: x.requires_grad, model.parameters())))\n",
    "    return l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9983dd-2281-4407-b2ef-1c2b15a40260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function_dl(batch):\n",
    "\n",
    "    #xs = batch[0].clone()\n",
    "    #ys = batch[1].clone()\n",
    "\n",
    "    xs = [item[0].unsqueeze(0) for item in batch]\n",
    "    ys = [item[1] for item in batch]\n",
    "    \n",
    "    xs = torch.cat(xs, dim=0)\n",
    "\n",
    "    y = torch.tensor(ys).view(-1, 1)\n",
    "    \n",
    "    Xs = [torch.rot90(xs, k = _, dims = [-2, -1]) for _ in range(4)]\n",
    "\n",
    "    return torch.cat(Xs, dim = 0), torch.cat([y for _ in range(4)], dim = 0).view(-1)\n",
    "\n",
    "def collate_function(batch):\n",
    "\n",
    "    xs = batch[0].clone()\n",
    "    ys = batch[1].clone().view(-1, 1)\n",
    "    \n",
    "    Xs = [torch.rot90(xs, k = _, dims = [-2, -1]) for _ in range(4)]\n",
    "\n",
    "    return torch.cat(Xs, dim = 0), torch.cat([ys for _ in range(4)], dim = 0).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d96a7-e57f-4664-9097-34775d7d83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489102ac-7fd0-4647-b666-229f1a7f61f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, optimizer):\n",
    "    TRAIN_LOSSES, TEST_LOSSES = [], []\n",
    "    TRAIN_ACCS, TEST_ACCS = [], []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_losses, test_losses = [], []\n",
    "        train_accs, test_accs = [], []\n",
    "\n",
    "        model.train() # Set up training mode\n",
    "\n",
    "        for batch in iter(train_dl):\n",
    "            # X, y = collate_function(batch)\n",
    "            X, y = batch\n",
    "            X, y = X.to(DEVICE), y.view(-1).to(DEVICE)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                y_pred = model(X)\n",
    "            \n",
    "            # Uncomment the line below if the criterion is nn.NLLLoss()\n",
    "            # y_pred = torch.log_softmax(y_pred, dim = -1)\n",
    "\n",
    "            # Compare actual targets and predicted targets to get the loss\n",
    "            train_loss = criterion(y_pred, y) #+ (l2_lambda * get_l2_loss(model))\n",
    "            # Backpropagate the loss\n",
    "            train_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            train_acc = accuracy_score(y.cpu().numpy(), y_pred.max(dim = -1).indices.cpu().numpy())\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "        \n",
    "        with torch.no_grad(): # Turn off computational graph\n",
    "            model.eval() # Set model to evaluation mode\n",
    "            for batch in iter(test_dl):\n",
    "                # X_, y_ = collate_function(batch)\n",
    "                X_, y_ = batch\n",
    "                X_, y_ = X_.to(DEVICE), y_.view(-1).to(DEVICE)\n",
    "    \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    y_pred_ = model(X_)\n",
    "                \n",
    "                # Uncomment the line below if the criterion is nn.NLLLoss()\n",
    "                # y_pred_ = torch.log_softmax(y_pred_, dim = -1)\n",
    "    \n",
    "                # Compare actual targets and predicted targets to get the loss\n",
    "                test_loss = criterion(y_pred_, y_) #+ (l2_lambda * get_l2_loss(model))\n",
    "                test_losses.append(test_loss.item())\n",
    "\n",
    "                test_acc = accuracy_score(y_.cpu().numpy(), y_pred_.max(dim = -1).indices.cpu().numpy())\n",
    "                test_accs.append(test_acc)\n",
    "\n",
    "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "        avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "\n",
    "        avg_train_acc = sum(train_accs) / len(train_accs)\n",
    "        avg_test_acc = sum(test_accs) / len(test_accs)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | Train loss: {avg_train_loss: .3f} | Test loss: {avg_test_loss: .3f} |\",\n",
    "            f\"Train accuracy: {avg_train_acc: .3f} | Test accuracy: {avg_test_acc: .3f} |\"\n",
    "        )\n",
    "\n",
    "        TRAIN_LOSSES.append(avg_train_loss)\n",
    "        TEST_LOSSES.append(avg_test_loss)\n",
    "\n",
    "        TRAIN_ACCS.append(avg_train_acc)\n",
    "        TEST_ACCS.append(avg_test_acc)\n",
    "\n",
    "    # Clear CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.clear_autocast_cache()\n",
    "\n",
    "    return {\n",
    "        \"loss\": [TRAIN_LOSSES, TEST_LOSSES],\n",
    "        \"accuracy\": [TRAIN_ACCS, TEST_ACCS],\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc1bb-ef27-4f4b-879f-eb3fd235378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Resnet-18 with finetuning\n",
    "model_results = training_loop(epochs = EPOCHS, optimizer = opt, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81524f-ed2c-46f3-abde-1bcb18907e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8849d-01fd-4eac-abf9-9914763cbb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(history, key = None):\n",
    "    if key is not None:\n",
    "        TRAIN_RESULTS, TEST_RESULTS = history[key]\n",
    "\n",
    "        plt.figure(figsize = (10, 3))\n",
    "\n",
    "        plt.plot(range(EPOCHS), TRAIN_RESULTS, label = f\"Training {key.capitalize()}\")\n",
    "        plt.plot(range(EPOCHS), TEST_RESULTS, label = f\"Test {key.capitalize()}\")\n",
    "\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(key.capitalize())\n",
    "\n",
    "        plt.title(key.capitalize() + \" Evolution for Train and Test Splits\", fontsize = 16)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show(); plt.close(\"all\")\n",
    "    else:\n",
    "        TRAIN_LOSSES, TEST_LOSSES = history[\"loss\"]\n",
    "        TRAIN_ACCS, TEST_ACCS = history[\"accuracy\"]\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (15, 4))\n",
    "\n",
    "        ax[0].plot(range(EPOCHS), TRAIN_LOSSES, label = \"Training Loss\")\n",
    "        ax[0].plot(range(EPOCHS), TEST_LOSSES, label = \"Test Loss\")\n",
    "\n",
    "        ax[0].set_xlabel(\"Epochs\")\n",
    "        ax[0].set_ylabel(\"Loss\")\n",
    "\n",
    "        ax[0].set_title(\"Loss Evolution for Train and Test Splits\", fontsize = 16)\n",
    "\n",
    "        ax[1].plot(range(EPOCHS), TRAIN_ACCS, label = \"Training Accuracy\")\n",
    "        ax[1].plot(range(EPOCHS), TEST_ACCS, label = \"Test Accuracy\")\n",
    "\n",
    "        ax[1].set_xlabel(\"Epochs\")\n",
    "        ax[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "        ax[1].set_title(\"Accuracy Evolution for Train and Test Splits\", fontsize = 16)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show(); plt.close(\"all\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faef653-d0fa-4513-962e-1322c0455f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216297a-6127-4950-8f70-b66230e813e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-13 with finetuning\n",
    "visualize_results(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478403b-bc32-42da-8c19-0675dcc91d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168b8ca-722b-44a6-936c-9de2202f2d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
