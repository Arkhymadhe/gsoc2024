{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6541e223-96bc-474f-8d3c-e2eb35553395",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Task 2: Deep Learning based Quark-Gluon Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30580cd2-ccb6-489e-b497-b569e6aef8d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb4764-db7b-4e71-a323-f8800ed6b150",
   "metadata": {},
   "source": [
    "● __Data Preparation__: Please train your model on 80% of the data and evaluate on the remaining 20%. Please make sure not to overfit on the test dataset - it will be checked with an independent sample.\n",
    "\n",
    "● __Model Training__: Train a __VGG13__ model and another model of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a03c7a1-152b-4930-bea2-4065727930e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f5d801-9381-4adf-9822-b7b9a8abcc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7115766-1e91-4e1b-865d-99e9f261d9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pyarrow.parquet as pq\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00ee46d-bd54-4996-8e69-fc4406ae00bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harkhymadhe/miniforge3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/harkhymadhe/miniforge3/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, ConcatDataset\n",
    "\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841733e-e77b-40e5-8130-c0fc5518ccfb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa990ebf-9d2e-4536-9349-be5b5cd2e53a",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Phase I: Data Preparation</h2>\n",
    "\n",
    "__Aim__: Please train your model on 80% of the data and evaluate on the remaining 20%. Please make sure not to overfit on the test dataset - it will be checked with an independent sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471f1c4-ee4c-4ec5-be3b-3aba6cbb35e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56a4e6-47d6-4169-93bf-d1af3b844cb5",
   "metadata": {},
   "source": [
    "First, the parquet files are downloaded and stored in the __./dataset/__ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c9d2464-c29c-470f-8947-413a3b18b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "file1 = \"dataset/QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet\"\n",
    "file2 = \"dataset/QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet\"\n",
    "file3 = \"dataset/QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467d160-b729-4ed5-afc6-e370384a09e7",
   "metadata": {},
   "source": [
    "A litle bit of experimentation showed that loading the Parquet files via __Pandas__ or basic __PyArrow__ was very inefficient and resulted in OOM errors. I attempt to bypass this via the more specialized __parquet__ subpackage in __PyArrow__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d48a7b4-3e02-473f-b6f0-e01ab3325661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "class ParquetDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.parquet = pq.ParquetFile(filename)\n",
    "        self.cols = None \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.parquet.read_row_group(index, columns=self.cols).to_pydict()\n",
    "        data['X_jets']= 1.*np.float32(data['X_jets'][0])#/data['mGG']\n",
    "        data['X_jets']=data['X_jets'][0][:80000]\n",
    "        \n",
    "        data = dict(data)\n",
    "        return torch.as_tensor(np.expand_dims(data[\"X_jets\"], axis = 0)), int(data[\"y\"][0])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.parquet.num_row_groups\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, filenames):\n",
    "        return ConcatDataset([cls(fname) for fname in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094f435-5dd3-452d-ad42-335b96a14156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22effa39-b37a-41ff-a878-f493cd81a4db",
   "metadata": {},
   "source": [
    "Loading the Parquet data using the __ParquetDataset__ class defined above is quite OK, but it makes actual file loading for multiple data points more cumbersome. A more efficient __BatchedParquetDataset__ is implemented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c2da50-9fbe-47a9-b000-e621cf6fb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "class BatchedParquetDataset(Dataset):\n",
    "    def __init__(self, filename, batch_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.parquet = pq.ParquetFile(filename)\n",
    "        self.cols = None\n",
    "        \n",
    "        self.size = self.parquet.num_row_groups\n",
    "\n",
    "        self.remainder = self.size % self.batch_size\n",
    "\n",
    "        self.batch_indices = list(range(0, self.size, self.batch_size))\n",
    "        self.batch_indices = list(\n",
    "            zip(\n",
    "                self.batch_indices,\n",
    "                self.batch_indices[1:] + [self.batch_indices[-1] + (self.remainder if self.remainder > 0 else self.batch_size)]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = range(*self.batch_indices[index])\n",
    "        data = self.parquet.read_row_groups(indexes, columns=self.cols).columns\n",
    "\n",
    "        image = torch.as_tensor(data[0].to_pylist())\n",
    "        targets = torch.as_tensor(data[-1].to_pylist(), dtype = torch.long)\n",
    "        \n",
    "        return image, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.batch_indices)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, filenames, batch_size):\n",
    "        return ConcatDataset([cls(filename = fname, batch_size = batch_size) for fname in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb28268f-27d3-4804-91ab-670b592aeef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187c07f6-40cf-4820-a065-9c032acb116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_data = BatchedParquetDataset.from_files(batch_size = batch_size, filenames = [file1, file2, file3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871c48cd-cbf7-4f41-9c8a-7b3e78bb28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = batched_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93286f3b-618f-4482-a227-c02e2836241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 125, 125])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b203264e-0e88-48ec-abfb-79458272dad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9b8860-9e15-46a4-bba1-7df846d188a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139392"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batched_data) * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5973ee-4296-40e9-ba7f-6adbd09ca11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b1a26a-100c-4d6d-8269-f1608e3590d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = random_split(batched_data, lengths = [.8, .2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdce5909-35c7-4a11-b3a9-043a82056471",
   "metadata": {},
   "source": [
    "class BatchedDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(super())\n",
    "\n",
    "    def __next__(self):\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0358ab91-c097-439f-b755-ca589c771d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = 1,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = 1,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283e96c-6014-4edb-8fbd-b613019d47c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6d0cbe1-be72-4142-8ed4-ff6a4c0a3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a5423d9-2446-4b8e-9a1f-af678b56dc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f11a2-3da0-46f0-a226-025d16b5c064",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e3a81-d696-47bd-a710-2e64a54342df",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Phase II: Model Training</h2>\n",
    "\n",
    "__Aim__: Train a VGG13 model and another model of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409bf0f8-d737-4a93-9b41-b46cc9f38671",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974b0d3-d1f2-40e2-bf8c-cdb5fc4e7be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "489af5bf-df43-4f0c-a0f7-c0bbed44befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harkhymadhe/miniforge3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/harkhymadhe/miniforge3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG13_Weights.IMAGENET1K_V1`. You can also use `weights=VGG13_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg13(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec74f777-3d22-4121-822d-0ce4703ed056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31daa2-4b22-4419-9527-cbefc634b28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "570c0c00-6992-4dac-8451-fa9f85e78139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleModel(nn.Module):\n",
    "    def __init__(self, model, freeze = False, out_features = 2, channels = 2, height = 32, width = 32):\n",
    "        super().__init__()\n",
    "        self.backbone = model\n",
    "        self.freeze = freeze\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.out_features = out_features\n",
    "        self.layer_norm = nn.LayerNorm([self.channels, self.height, self.width])\n",
    "\n",
    "        if self.freeze:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad_(False)\n",
    "\n",
    "        in_ = self.backbone.classifier[-1].in_features\n",
    "        self.backbone.classifier[-1] = nn.Linear(in_features = in_, out_features = out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c4083b6-d461-43ca-81bd-977016c24bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for (name, weights) in filter(lambda x: x[1].requires_grad, model.named_parameters()):\n",
    "        if name.split(\".\")[1] not in [\"fc\", \"conv1\"]:\n",
    "            continue\n",
    "        try:\n",
    "            nn.init.kaiming_normal_(weights)\n",
    "        except:\n",
    "            nn.init.normal_(weights, 0., 0.05)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d81c61-1c91-4def-b92b-adfda8a565ef",
   "metadata": {},
   "source": [
    "In this notebook, the pretrained weights will be finetuned. This is in contrast to the previous one, where the weights were kept frozen. Also, the learning rate is increased from 1e-4 to 1e-3.\n",
    "\n",
    "__Update 1__: A learning rate of 1e-3 may be too small for non-frozen weights. I will now attempt to freeze the weights and leave the learning rate as is. Freezing the weights might even speed up training.\n",
    "\n",
    "__Update 2__: Freezing all the weights seem to have reduced performance. This might be due to the fact that the data we have here is not actualy a set of images, even though they seem so. It appears I might have to unfreeze the weights and increase the learning rate a bit.\n",
    "\n",
    "__Update 3__: Applying the ideas from __Update 2__ led to even worse performance! Returning the state of training to __Update 1__..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8ab6731-7f4c-4a09-98dc-6e93d1c6c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "l2_lambda = 1e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# Optimizer hyperparameters\n",
    "LR = 1e-3\n",
    "FACTOR = 100\n",
    "AMSGRAD = False\n",
    "BETAS = (.9, .999)\n",
    "FREEZE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60735ef7-42ae-489b-8827-81f7e85aeaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ParticleModel(\n",
    "    model = model,\n",
    "    freeze = FREEZE,\n",
    "    channels = 3,\n",
    "    height = 125,\n",
    "    width = 125\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e5558d6-a906-4581-99e8-418af4de7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0642a379-eb85-4d39-b45d-9ac0db66645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate optimizer\n",
    "opt = optim.AdamW(\n",
    "    params = [{\n",
    "        \"params\" : model.backbone.parameters(),\n",
    "        \"lr\": LR\n",
    "    }],\n",
    "    lr=LR/FACTOR,\n",
    "    amsgrad = AMSGRAD,\n",
    "    betas = BETAS,\n",
    "    weight_decay = l2_lambda,\n",
    "    fused = True\n",
    ")\n",
    "\n",
    "# scheduler = optim.lt_scheduler.Cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "971d96a7-e57f-4664-9097-34775d7d83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "489102ac-7fd0-4647-b666-229f1a7f61f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, optimizer):\n",
    "    TRAIN_LOSSES, TEST_LOSSES = [], []\n",
    "    TRAIN_ACCS, TEST_ACCS = [], []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_losses, test_losses = [], []\n",
    "        train_accs, test_accs = [], []\n",
    "\n",
    "        model.train() # Set up training mode\n",
    "\n",
    "        for batch in iter(train_dl):\n",
    "            # X, y = collate_function(batch)\n",
    "            X, y = batch\n",
    "            X, y = X.squeeze().to(DEVICE), y.view(-1).to(DEVICE)\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            train_loss = criterion(y_pred, y.to(torch.long)) # Compare actual targets and predicted targets to get the loss\n",
    "            train_loss.backward() # Backpropagate the loss\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_losses.append(train_loss.detach().item())\n",
    "\n",
    "            train_acc = accuracy_score(y.cpu().numpy(), y_pred.max(dim = -1).indices.cpu().numpy())\n",
    "            train_accs.append(train_acc)\n",
    "\n",
    "        # Persist model architecture\n",
    "        torch.save(model.state_dict(), f\"epoch_{epoch}_vgg_model.pt\")\n",
    "\n",
    "        with torch.no_grad(): # Turn off computational graph\n",
    "            model.eval() # Set model to evaluation mode\n",
    "            for batch in iter(test_dl):\n",
    "                # X_, y_ = collate_function(batch)\n",
    "                X_, y_ = batch\n",
    "                X_, y_ = X_.squeeze().to(DEVICE), y_.view(-1).to(DEVICE)\n",
    "    \n",
    "                y_pred_ = model(X_)\n",
    "    \n",
    "                test_loss = criterion(y_pred_, y_.to(torch.long)) # Compare actual targets and predicted targets to get the loss\n",
    "                test_losses.append(test_loss.item())\n",
    "\n",
    "                test_acc = accuracy_score(y_.cpu().numpy(), y_pred_.max(dim = -1).indices.cpu().numpy())\n",
    "                test_accs.append(test_acc)\n",
    "\n",
    "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "        avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "\n",
    "        avg_train_acc = sum(train_accs) / len(train_accs)\n",
    "        avg_test_acc = sum(test_accs) / len(test_accs)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | Train loss: {avg_train_loss: .3f} | Test loss: {avg_test_loss: .3f} |\",\n",
    "            f\"Train accuracy: {avg_train_acc: .3f} | Test accuracy: {avg_test_acc: .3f} |\"\n",
    "        )\n",
    "\n",
    "        TRAIN_LOSSES.append(avg_train_loss)\n",
    "        TEST_LOSSES.append(avg_test_loss)\n",
    "\n",
    "        TRAIN_ACCS.append(avg_train_acc)\n",
    "        TEST_ACCS.append(avg_test_acc)\n",
    "\n",
    "    # Clear CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.clear_autocast_cache()\n",
    "\n",
    "    return {\n",
    "        \"loss\": [TRAIN_LOSSES, TEST_LOSSES],\n",
    "        \"accuracy\": [TRAIN_ACCS, TEST_ACCS],\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fc1bb-ef27-4f4b-879f-eb3fd235378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train loss:  0.605 | Test loss:  0.560 | Train accuracy:  0.699 | Test accuracy:  0.719 |\n",
      "Epoch: 2 | Train loss:  0.573 | Test loss:  0.558 | Train accuracy:  0.715 | Test accuracy:  0.724 |\n",
      "Epoch: 3 | Train loss:  0.578 | Test loss:  0.558 | Train accuracy:  0.716 | Test accuracy:  0.725 |\n",
      "Epoch: 4 | Train loss:  0.569 | Test loss:  0.557 | Train accuracy:  0.720 | Test accuracy:  0.727 |\n",
      "Epoch: 5 | Train loss:  0.563 | Test loss:  0.558 | Train accuracy:  0.725 | Test accuracy:  0.727 |\n",
      "Epoch: 6 | Train loss:  0.564 | Test loss:  0.556 | Train accuracy:  0.723 | Test accuracy:  0.724 |\n",
      "Epoch: 7 | Train loss:  0.559 | Test loss:  0.558 | Train accuracy:  0.727 | Test accuracy:  0.725 |\n",
      "Epoch: 8 | Train loss:  0.559 | Test loss:  0.552 | Train accuracy:  0.728 | Test accuracy:  0.728 |\n",
      "Epoch: 9 | Train loss:  0.556 | Test loss:  0.552 | Train accuracy:  0.729 | Test accuracy:  0.729 |\n",
      "Epoch: 10 | Train loss:  0.554 | Test loss:  0.551 | Train accuracy:  0.731 | Test accuracy:  0.728 |\n",
      "Epoch: 11 | Train loss:  0.554 | Test loss:  0.556 | Train accuracy:  0.732 | Test accuracy:  0.728 |\n",
      "Epoch: 12 | Train loss:  0.553 | Test loss:  0.555 | Train accuracy:  0.732 | Test accuracy:  0.733 |\n",
      "Epoch: 13 | Train loss:  0.556 | Test loss:  0.552 | Train accuracy:  0.730 | Test accuracy:  0.727 |\n",
      "Epoch: 14 | Train loss:  0.556 | Test loss:  0.569 | Train accuracy:  0.731 | Test accuracy:  0.723 |\n",
      "Epoch: 15 | Train loss:  0.550 | Test loss:  0.550 | Train accuracy:  0.734 | Test accuracy:  0.730 |\n"
     ]
    }
   ],
   "source": [
    "# Train VGG-13 with finetuning\n",
    "model_results = training_loop(epochs = EPOCHS, optimizer = opt, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81524f-ed2c-46f3-abde-1bcb18907e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist model\n",
    "torch.save(model_results[\"model\"].state_dict(), \"final_epoch_vgg_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8849d-01fd-4eac-abf9-9914763cbb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(history, key = None):\n",
    "    if key is not None:\n",
    "        TRAIN_RESULTS, TEST_RESULTS = history[key]\n",
    "\n",
    "        plt.figure(figsize = (10, 3))\n",
    "\n",
    "        plt.plot(range(EPOCHS), TRAIN_RESULTS, label = f\"Training {key.capitalize()}\")\n",
    "        plt.plot(range(EPOCHS), TEST_RESULTS, label = f\"Test {key.capitalize()}\")\n",
    "\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(key.capitalize())\n",
    "\n",
    "        plt.title(key.capitalize() + \" Evolution for Train and Test Splits\", fontsize = 16)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show(); plt.close(\"all\")\n",
    "    else:\n",
    "        TRAIN_LOSSES, TEST_LOSSES = history[\"loss\"]\n",
    "        TRAIN_ACCS, TEST_ACCS = history[\"accuracy\"]\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (15, 4))\n",
    "\n",
    "        ax[0].plot(range(EPOCHS), TRAIN_LOSSES, label = \"Training Loss\")\n",
    "        ax[0].plot(range(EPOCHS), TEST_LOSSES, label = \"Test Loss\")\n",
    "\n",
    "        ax[0].set_xlabel(\"Epochs\")\n",
    "        ax[0].set_ylabel(\"Loss\")\n",
    "\n",
    "        ax[0].set_title(\"Loss Evolution for Train and Test Splits\", fontsize = 16)\n",
    "\n",
    "        ax[1].plot(range(EPOCHS), TRAIN_ACCS, label = \"Training Accuracy\")\n",
    "        ax[1].plot(range(EPOCHS), TEST_ACCS, label = \"Test Accuracy\")\n",
    "\n",
    "        ax[1].set_xlabel(\"Epochs\")\n",
    "        ax[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "        ax[1].set_title(\"Accuracy Evolution for Train and Test Splits\", fontsize = 16)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show(); plt.close(\"all\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faef653-d0fa-4513-962e-1322c0455f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216297a-6127-4950-8f70-b66230e813e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-13 with finetuning\n",
    "visualize_results(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478403b-bc32-42da-8c19-0675dcc91d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168b8ca-722b-44a6-936c-9de2202f2d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
